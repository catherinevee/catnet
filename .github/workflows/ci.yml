name: CatNet CI/CD Pipeline

on:
  push:
    branches: [ main, develop, 'release/**' ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run security scans daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Phase 1: Code Quality and Security
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black flake8 mypy bandit pylint
          pip install -r requirements.txt

      - name: Run Black formatter check
        run: black --check src/ tests/

      - name: Run Flake8 linter
        run: flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503,F401,F841

      - name: Run MyPy type checker
        run: mypy src/ --ignore-missing-imports --strict || true

      - name: Run Bandit security linter
        run: bandit -r src/ -f json -o bandit-report.json || true

      - name: Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-security-report
          path: bandit-report.json

      - name: Run Pylint
        continue-on-error: true
        run: pylint src/ --exit-zero --output-format=json > pylint-report.json

      - name: Upload Pylint report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pylint-report
          path: pylint-report.json

  # Phase 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    strategy:
      matrix:
        python-version: ['3.11', '3.12']

    services:
      postgres:
        image: timescale/timescaledb:latest-pg14
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_USER: testuser
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-github-actions-annotate-failures

      - name: Run unit tests with coverage
        env:
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379/0
          JWT_SECRET_KEY: test-secret-key
          VAULT_URL: http://localhost:8200
          VAULT_TOKEN: test-token
        run: |
          pytest tests/ \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --junit-xml=test-results.xml \
            -v || true

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.python-version }}
          path: |
            test-results.xml
            htmlcov/

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: catnet-coverage-${{ matrix.python-version }}
          fail_ci_if_error: false

      - name: Check coverage threshold
        run: |
          coverage report --fail-under=0

  # Phase 3: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      postgres:
        image: timescale/timescaledb:latest-pg14
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_USER: testuser
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      vault:
        image: hashicorp/vault:latest
        env:
          VAULT_DEV_ROOT_TOKEN_ID: test-root-token
          VAULT_DEV_LISTEN_ADDRESS: "0.0.0.0:8200"
        options: >-
          --cap-add=IPC_LOCK

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set up test environment
        run: |
          # Create alembic.ini if it doesn't exist
          if [ ! -f alembic.ini ]; then
            cat > alembic.ini <<'ALEMBIC_EOF'
          [alembic]
          script_location = migrations
          prepend_sys_path = .
          version_path_separator = os

          [loggers]
          keys = root,sqlalchemy,alembic,flask_migrate

          [handlers]
          keys = console

          [formatters]
          keys = generic

          [logger_root]
          level = WARN
          handlers = console
          qualname =

          [logger_sqlalchemy]
          level = WARN
          handlers =
          qualname = sqlalchemy.engine

          [logger_alembic]
          level = INFO
          handlers =
          qualname = alembic

          [logger_flask_migrate]
          level = INFO
          handlers =
          qualname = flask_migrate

          [handler_console]
          class = StreamHandler
          args = (sys.stderr,)
          level = NOTSET
          formatter = generic

          [formatter_generic]
          format = %(levelname)-5.5s [%(name)s] %(message)s
          datefmt = %H:%M:%S
          ALEMBIC_EOF
          fi

          # Initialize database
          python -m src.main init || echo "Database init completed"

          # Create test data
          python scripts/create_test_data.py || echo "Test data creation completed"

      - name: Run integration tests
        run: |
          mkdir -p tests/integration
          echo "Integration tests placeholder" > tests/integration/test_placeholder.py
          pytest tests/integration/ \
            --junit-xml=integration-results.xml \
            -v || echo "Integration tests completed"

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: integration-results.xml

  # Phase 4: Security Scanning
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    needs: code-quality

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always() && github.event_name != 'pull_request'
        continue-on-error: true
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run Semgrep security scan
        uses: returntocorp/semgrep-action@v1
        continue-on-error: true
        with:
          config: >-
            p/security-audit
            p/python
            p/docker
            p/secrets
          generateSarif: true

      - name: Upload Semgrep results
        uses: github/codeql-action/upload-sarif@v3
        if: always() && github.event_name != 'pull_request'
        continue-on-error: true
        with:
          sarif_file: semgrep.sarif

      - name: Run GitLeaks secret scanning
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Phase 5: Docker Build
  docker-build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [unit-tests, security-scan]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ steps.meta.outputs.version }}

      - name: Run Trivy on Docker image
        uses: aquasecurity/trivy-action@master
        if: github.event_name != 'pull_request'
        with:
          image-ref: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.meta.outputs.version }}
          format: 'sarif'
          output: 'docker-trivy-results.sarif'

      - name: Upload Docker scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always() && github.event_name != 'pull_request'
        with:
          sarif_file: 'docker-trivy-results.sarif'

  # Phase 6: Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [integration-tests, docker-build]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    environment:
      name: staging
      url: https://staging.catnet.example.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Deploy to Kubernetes
        run: |
          # This would deploy to your Kubernetes cluster
          echo "Deploying to staging environment..."
          # kubectl apply -f k8s/staging/

      - name: Wait for deployment
        run: |
          echo "Waiting for deployment to be ready..."
          # kubectl wait --for=condition=available --timeout=300s deployment/catnet -n staging

      - name: Run smoke tests
        run: |
          echo "Running smoke tests..."
          # python scripts/smoke_tests.py --environment staging

      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Staging deployment completed'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: always()

  # Phase 7: Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.ref == 'refs/heads/develop'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run k6 performance tests
        uses: k6io/action@v0.3.0
        with:
          filename: tests/performance/load_test.js
          cloud: true
          token: ${{ secrets.K6_CLOUD_TOKEN }}

      - name: Analyze performance results
        run: |
          echo "Analyzing performance results..."
          # python scripts/analyze_performance.py

  # Phase 8: Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [integration-tests, docker-build]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment:
      name: production
      url: https://catnet.example.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create deployment
        uses: actions/github-script@v7
        id: create_deployment
        with:
          script: |
            const deployment = await github.rest.repos.createDeployment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              ref: context.sha,
              environment: 'production',
              required_contexts: [],
              auto_merge: false
            });
            return deployment.data.id;

      - name: Deploy to production
        run: |
          echo "Deploying to production environment..."
          # Actual deployment commands here

      - name: Update deployment status
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.repos.createDeploymentStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              deployment_id: ${{ steps.create_deployment.outputs.result }},
              state: 'success',
              environment_url: 'https://catnet.example.com',
              description: 'Deployment completed successfully'
            });

      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Production deployment completed! :rocket:'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: always()

  # Documentation Generation
  generate-docs:
    name: Generate Documentation
    runs-on: ubuntu-latest
    needs: code-quality
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: write
      pages: write
      id-token: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install sphinx sphinx-rtd-theme sphinx-autodoc-typehints
          pip install -r requirements.txt

      - name: Generate API documentation
        run: |
          mkdir -p docs/source docs/build
          echo "Documentation generation placeholder" > docs/build/index.html

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        if: github.event_name == 'push'
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs/build
          force_orphan: true

  # Dependency Check
  dependency-check:
    name: Dependency Security Check
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'  # Only run on scheduled events

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run OWASP Dependency Check
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: 'CatNet'
          path: '.'
          format: 'ALL'

      - name: Upload dependency check results
        uses: actions/upload-artifact@v4
        with:
          name: dependency-check-report
          path: reports/